READ INPUT FILE  datasets/ml1m/test/train.txt ...
user_id  0 ~ 6039  [num:  802085  (unique:  6040 )]
item_id  0 ~ 3414  [num:  802085  (unique:  3415 )]
SET ITEM PADDING...
user_id  0 ~ 6039  [num:  802085  (unique:  6040 )]
item_id  1 ~ 3415  [num:  802085  (unique:  3416 )]
READ INPUT FILE  datasets/ml1m/test/test.txt ...
user_id  0 ~ 6039  [num:  197521  (unique:  6040 )]
item_id  1 ~ 3415  [num:  197521  (unique:  3415 )]
Namespace(L=5, T=3, ac_conv='relu', ac_fc='relu', batch_size=512, d=50, drop=0.5, l2=1e-06, learning_rate=0.001, n_iter=1, neg_samples=3, nh=16, nv=0, seed=1234, test_root='datasets/ml1m/test/test.txt', train_root='datasets/ml1m/test/train.txt', use_cuda=True)
total training instances: 759805
Caser(
  (user_embeddings): Embedding(6040, 50)
  (item_embeddings): Embedding(3416, 50)
  (conv_h): ModuleList(
    (0): Conv2d(1, 16, kernel_size=(1, 50), stride=(1, 1))
    (1): Conv2d(1, 16, kernel_size=(2, 50), stride=(1, 1))
    (2): Conv2d(1, 16, kernel_size=(3, 50), stride=(1, 1))
    (3): Conv2d(1, 16, kernel_size=(4, 50), stride=(1, 1))
    (4): Conv2d(1, 16, kernel_size=(5, 50), stride=(1, 1))
  )
  (fc1): Linear(in_features=80, out_features=50, bias=True)
  (W2): Embedding(3416, 100)
  (b2): Embedding(3416, 1)
  (dropout): Dropout(p=0.5)
)
Epoch 1 [93.1 s]	loss=0.8185, map=0.0982, prec@1=0.1767, prec@5=0.1495, prec@10=0.1354, recall@1=0.0087, recall@5=0.0344, recall@10=0.0622, [106.1 s]
Epoch 1 [93.1 s]	loss=0.8185, map=0.0982, prec@1=0.1767, prec@5=0.1495, prec@10=0.1354, recall@1=0.0087, recall@5=0.0344, recall@10=0.0622, [106.1 s] <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>
--------------end--------------

 <_io.TextIOWrapper name='log/2018-12-05 16:10:02.173688.txt' mode='w' encoding='UTF-8'>
--------------end--------------

 <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>
